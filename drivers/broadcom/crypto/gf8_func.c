/*
 * $Copyright Broadcom Corporation$
 *
 */
#include <arch/cpu.h>
#include <crypto/crypto.h>
#include "crypto_sw_utils.h"
#include "gf8_func.h"

#ifdef __GF8_FUNC_H__

/*
 * To wrap code with dummy operations
 */
#if (1)
#define  __gf_dummy_op(op0, op1, x, y, z, expr) \
	{							\
		volatile int _i, _d0, _d1, _d2;		\
		_i = (x op0 y) & 0x07;				\
		_d1 = z;					\
		_d2 = x;					\
								\
		do {						\
			_d0 = (_d1 op1 _d2) op1 _i;		\
			_d1 = (_d0 op0 _d1);			\
			_i--;					\
			_d2 = (_d0 op1 _d2) & (_d1 op0 _i);	\
		} while (_i > 0);				\
		expr;						\
		_d2 = (_d0 op1 _d1) op0 (_d1 op0 _i);		\
	}
#else
#define  __gf_dummy_op(op0, op1, x, y, z, expr) {expr; }
#endif

_masked_invf_t _masked_aes_invf = {
	.tbl = {
		0x00, 0x01, 0x8D, 0xF6, 0xCB, 0x52, 0x7B, 0xD1,
		0xE8, 0x4F, 0x29, 0xC0, 0xB0, 0xE1, 0xE5, 0xC7,
		0x74, 0xB4, 0xAA, 0x4B, 0x99, 0x2B, 0x60, 0x5F,
		0x58, 0x3F, 0xFD, 0xCC, 0xFF, 0x40, 0xEE, 0xB2,
		0x3A, 0x6E, 0x5A, 0xF1, 0x55, 0x4D, 0xA8, 0xC9,
		0xC1, 0x0A, 0x98, 0x15, 0x30, 0x44, 0xA2, 0xC2,
		0x2C, 0x45, 0x92, 0x6C, 0xF3, 0x39, 0x66, 0x42,
		0xF2, 0x35, 0x20, 0x6F, 0x77, 0xBB, 0x59, 0x19,
		0x1D, 0xFE, 0x37, 0x67, 0x2D, 0x31, 0xF5, 0x69,
		0xA7, 0x64, 0xAB, 0x13, 0x54, 0x25, 0xE9, 0x09,
		0xED, 0x5C, 0x05, 0xCA, 0x4C, 0x24, 0x87, 0xBF,
		0x18, 0x3E, 0x22, 0xF0, 0x51, 0xEC, 0x61, 0x17,
		0x16, 0x5E, 0xAF, 0xD3, 0x49, 0xA6, 0x36, 0x43,
		0xF4, 0x47, 0x91, 0xDF, 0x33, 0x93, 0x21, 0x3B,
		0x79, 0xB7, 0x97, 0x85, 0x10, 0xB5, 0xBA, 0x3C,
		0xB6, 0x70, 0xD0, 0x06, 0xA1, 0xFA, 0x81, 0x82,
		0x83, 0x7E, 0x7F, 0x80, 0x96, 0x73, 0xBE, 0x56,
		0x9B, 0x9E, 0x95, 0xD9, 0xF7, 0x02, 0xB9, 0xA4,
		0xDE, 0x6A, 0x32, 0x6D, 0xD8, 0x8A, 0x84, 0x72,
		0x2A, 0x14, 0x9F, 0x88, 0xF9, 0xDC, 0x89, 0x9A,
		0xFB, 0x7C, 0x2E, 0xC3, 0x8F, 0xB8, 0x65, 0x48,
		0x26, 0xC8, 0x12, 0x4A, 0xCE, 0xE7, 0xD2, 0x62,
		0x0C, 0xE0, 0x1F, 0xEF, 0x11, 0x75, 0x78, 0x71,
		0xA5, 0x8E, 0x76, 0x3D, 0xBD, 0xBC, 0x86, 0x57,
		0x0B, 0x28, 0x2F, 0xA3, 0xDA, 0xD4, 0xE4, 0x0F,
		0xA9, 0x27, 0x53, 0x04, 0x1B, 0xFC, 0xAC, 0xE6,
		0x7A, 0x07, 0xAE, 0x63, 0xC5, 0xDB, 0xE2, 0xEA,
		0x94, 0x8B, 0xC4, 0xD5, 0x9D, 0xF8, 0x90, 0x6B,
		0xB1, 0x0D, 0xD6, 0xEB, 0xC6, 0x0E, 0xCF, 0xAD,
		0x08, 0x4E, 0xD7, 0xE3, 0x5D, 0x50, 0x1E, 0xB3,
		0x5B, 0x23, 0x38, 0x34, 0x68, 0x46, 0x03, 0x8C,
		0xDD, 0x9C, 0x7D, 0xA0, 0xCD, 0x1A, 0x41, 0x1C}
	,
	.x1 = 0,
	.x2 = 0,
	.cnt = 0
};

_masked_invf_t _masked_G_invf = {
	.tbl = {
		0x00, 0x01, 0xB1, 0xDE, 0xE9, 0x4A, 0x6F, 0x8C,
		0xC5, 0xA5, 0x25, 0xC1, 0x86, 0x54, 0x46, 0xE7,
		0xD3, 0x5D, 0xE3, 0x85, 0xA3, 0x34, 0xD1, 0xED,
		0x43, 0xA6, 0x2A, 0x63, 0x23, 0x9E, 0xC2, 0x77,
		0xD8, 0x2D, 0x9F, 0x1C, 0xC0, 0x0A, 0xF3, 0xAB,
		0xE0, 0xB5, 0x1A, 0x62, 0xD9, 0x21, 0xC7, 0xBD,
		0x90, 0x56, 0x53, 0xEA, 0x15, 0xA2, 0x80, 0x79,
		0xA0, 0x5B, 0x4F, 0xE5, 0x61, 0x49, 0x8A, 0xCD,
		0x6C, 0x9A, 0xA7, 0x18, 0xFE, 0x7C, 0x0E, 0xE6,
		0x60, 0x3D, 0x05, 0xE8, 0xC8, 0x82, 0xE4, 0x3A,
		0x70, 0x6A, 0xEB, 0x32, 0x0D, 0x87, 0x31, 0x91,
		0xDD, 0xF6, 0xA1, 0x39, 0xD2, 0x11, 0xEF, 0xBF,
		0x48, 0x3C, 0x2B, 0x1B, 0x98, 0xD5, 0x75, 0x97,
		0xBB, 0xB8, 0x51, 0x71, 0x40, 0x9B, 0x8D, 0x06,
		0x50, 0x6B, 0x9C, 0x8E, 0x96, 0x66, 0xC3, 0x1F,
		0x81, 0x37, 0x95, 0xB2, 0x45, 0xFF, 0xD7, 0x88,
		0x36, 0x78, 0x4D, 0xC9, 0xE2, 0x13, 0x0C, 0x55,
		0x7F, 0xD6, 0x3E, 0xCC, 0x07, 0x6E, 0x73, 0x9D,
		0x30, 0x57, 0xAF, 0xF8, 0xB3, 0x7A, 0x74, 0x67,
		0x64, 0xD4, 0x41, 0x6D, 0x72, 0x8F, 0x1D, 0x22,
		0x38, 0x5A, 0x35, 0x14, 0xC4, 0x09, 0x19, 0x42,
		0xB7, 0xAC, 0xF2, 0x27, 0xA9, 0xB6, 0xF9, 0x92,
		0xDF, 0x02, 0x7B, 0x94, 0xE1, 0x29, 0xAD, 0xA8,
		0x69, 0xBA, 0xB9, 0x68, 0xC6, 0x2F, 0xEE, 0x5F,
		0x24, 0x0B, 0x1E, 0x76, 0xA4, 0x08, 0xBC, 0x2E,
		0x4C, 0x83, 0xDB, 0xFD, 0x8B, 0x3F, 0xFA, 0xF5,
		0xEC, 0x16, 0x5C, 0x10, 0x99, 0x65, 0x89, 0x7E,
		0x20, 0x2C, 0xFC, 0xCA, 0xF7, 0x58, 0x03, 0xB0,
		0x28, 0xB4, 0x84, 0x12, 0x4E, 0x3B, 0x47, 0x0F,
		0x4B, 0x04, 0x33, 0x52, 0xD0, 0x17, 0xBE, 0x5E,
		0xF1, 0xF0, 0xAA, 0x26, 0xFB, 0xCF, 0x59, 0xDC,
		0x93, 0xAE, 0xCE, 0xF4, 0xDA, 0xCB, 0x44, 0x7D}
	,
	.x1 = 0,
	.x2 = 0,
	.cnt = 0
};

_masked_invf_t _masked_G2_invf = {
	.tbl = {
		0x00, 0x01, 0xF3, 0xA2, 0x8A, 0xC3, 0x51, 0x99,
		0x45, 0x77, 0x92, 0x58, 0xDB, 0x2E, 0xBF, 0x41,
		0xD1, 0x3F, 0xC8, 0xA9, 0x49, 0x33, 0x2C, 0x1A,
		0x9E, 0x90, 0x17, 0x2D, 0xAC, 0x95, 0xD3, 0x47,
		0x9B, 0x3D, 0xEC, 0x43, 0x64, 0x9D, 0xA7, 0x73,
		0xD7, 0x6E, 0xEA, 0x70, 0x16, 0x1B, 0x0D, 0xDA,
		0x4F, 0xCB, 0x48, 0x15, 0xF8, 0x67, 0xE5, 0x52,
		0x56, 0xAB, 0xB9, 0x88, 0x9A, 0x21, 0xD0, 0x11,
		0xBE, 0x0F, 0xED, 0x23, 0x76, 0x08, 0xD2, 0x1F,
		0x32, 0x14, 0xBD, 0xC4, 0xA0, 0x78, 0xCA, 0x30,
		0x98, 0x06, 0x37, 0xE4, 0x75, 0xAE, 0x38, 0xAA,
		0x0B, 0x93, 0xFE, 0xC6, 0xF5, 0x83, 0x6D, 0x80,
		0xD4, 0xF1, 0x96, 0xB6, 0x24, 0x9C, 0xF9, 0x35,
		0x7C, 0x8C, 0xC0, 0xDE, 0x81, 0x5E, 0x29, 0xD6,
		0x2B, 0xEB, 0xA6, 0x27, 0xAF, 0x54, 0x44, 0x09,
		0x4D, 0xA1, 0xE3, 0x87, 0x68, 0x8D, 0xFB, 0xB4,
		0x5F, 0x6C, 0xF4, 0x5D, 0x85, 0x84, 0xE2, 0x7B,
		0x3B, 0xB8, 0x04, 0xC2, 0x69, 0x7D, 0xFC, 0xCC,
		0x19, 0x9F, 0x0A, 0x59, 0xAD, 0x1D, 0x62, 0xB7,
		0x50, 0x07, 0x3C, 0x20, 0x65, 0x25, 0x18, 0x91,
		0x4C, 0x79, 0x03, 0xF2, 0xE8, 0xCF, 0x72, 0x26,
		0xC9, 0x13, 0x57, 0x39, 0x1C, 0x94, 0x55, 0x74,
		0xF6, 0xEF, 0xBA, 0xD8, 0x7F, 0xFA, 0x63, 0x97,
		0x89, 0x3A, 0xB2, 0xD9, 0xC5, 0x4A, 0x40, 0x0E,
		0x6A, 0xDF, 0x8B, 0x05, 0x4B, 0xBC, 0x5B, 0xFF,
		0x12, 0xA8, 0x4E, 0x31, 0x8F, 0xFD, 0xE9, 0xA5,
		0x3E, 0x10, 0x46, 0x1E, 0x60, 0xF0, 0x6F, 0x28,
		0xB3, 0xBB, 0x2F, 0x0C, 0xE7, 0xE1, 0x6B, 0xC1,
		0xE6, 0xDD, 0x86, 0x7A, 0x53, 0x36, 0xE0, 0xDC,
		0xA4, 0xCE, 0x2A, 0x71, 0x22, 0x42, 0xF7, 0xB1,
		0xD5, 0x61, 0xA3, 0x02, 0x82, 0x5C, 0xB0, 0xEE,
		0x34, 0x66, 0xB5, 0x7E, 0x8E, 0xCD, 0x5A, 0xC7}
	,
	.x1 = 0,
	.x2 = 0,
	.cnt = 0
};

/*
 * p1(x) * p2(x) mod g(x)
 * Use the accociative property of multiplication to simplify the code
 */

#if (1)	/* turn on for DPA */
#if (1)	/* two different styles */
u8_t gf8_mul(u8_t p0, u8_t p1, u8_t g, u8_t x1)
{
	int i;
	volatile u8_t mask = 0x01;
	volatile u16_t m = 0, t = 0, m1 = 0, t1 = 0, m2 = 0, t2 = 0;
	u8_t r0, r1, r2;
	u32_t random;

	__brcm_rnd_delay();

	bcm_rng_readwords(&random, 1);
	r0 = 0;
	r1 = (u8_t) (random & 0xFF);
	r2 = (u8_t) ((random >> 8) & 0xFF);

	__gf_dummy_op(^, ^, r0, r1, r2, {
		      r0 = r1 ^ r2 ^ p0;
		      });

	mask = 0x01;

	__gf_dummy_op(&, &, t, t1, t2, {
		t = r0;
		if (p1 & 0x01)
			m = t; }
	);
	__gf_dummy_op(&, &, t2, t1, t, {
		t1 = r1;
		if (p1 & 0x01)
			m1 = t1; }
	);
	__gf_dummy_op(&, &, t, t2, t1, {
		t2 = r2;
		if (p1 & 0x01)
			m2 = t2; }
	);

	for (i = 1; i < 8; i++) {
		mask <<= 1;
		__gf_dummy_op(&, &, t2, t1, t, {
			t <<= 1;
			if (t & 0x100)
				t ^= g;
			if (p1 & mask)
				m ^= t; }
		);
		__brcm_rnd_delay();

		__gf_dummy_op(&, &, t1, t, t2, {
				t1 <<= 1;
				if (t1 & 0x100)
					t1 ^= g;
				if (p1 & mask)
					m1 ^= t1;
			}
		);
		__gf_dummy_op(&, &, t1, t, t2, {
				t2 <<= 1;
				if (t2 & 0x100)
					t2 ^= g;
				if (p1 & mask)
					m2 ^= t2;
			}
		);
	}

	__gf_dummy_op(^, ^, t1, t, t2, {
		      m = m ^ m1 ^ m2 ^ x1;
		}
	);

	__brcm_rnd_delay();
	return m;
}

#else
u8_t gf8_mul(u8_t p0, u8_t p1, u8_t g, u8_t x1, _masked_invf_t *invf)
{
	int i;
	u16_t a[2], b[2];
	volatile u16_t m, t, mm;
	volatile u8_t mask;

	mask = 0x01;
	m = 0;
	__gf_dummy_op(^, ^, invf->x1, invf->x2, invf->cnt, {
			a[0] = x1;
			a[1] = p0;
			b[0] = 0x0;
			b[1] = 0xff;
			m = (p0 & 0x01) | ((p0 & 0x02) >> 1) |
			    ((p0 & 0x04) >> 2) | ((p0 & 0x08) >> 3);
		}
	);
	__gf_dummy_op(^, ^, invf->x1, invf->x2, invf->cnt, {
			m |= ((p0 & 0x10) >> 4) | ((p0 & 0x20) >> 5) |
			     ((p0 & 0x40) >> 6) | ((p0 & 0x80) > 7);
			t = a[m];
			mm = b[m];
		}
	);

	mask = 0x01;
	m = (p1 & 0x01) ? t : 0;

	for (i = 1; i < 8; i++) {
		mask <<= 1;
		t <<= 1;

		if (t & 0x100)
			t ^= g;
		if (p1 & mask)
			m ^= t;
	}
	return ((u8_t) (m & mm) ^ x1);	/* 3-28 */
}
#endif
#else /* straight, no countermeasure */
u8_t gf8_mul(u8_t p0, u8_t p1, u8_t g)
{
	int i;
	u8_t mask = 0x01;
	u16_t m = 0, t = p0;

	m = (p1 & 0x01) ? p0 : 0;

	/* a*(x7+x6...) = a*x7+a*x6... then the result can be accumulated */
	for (i = 1; i < 8; i++) {
		mask <<= 1;
		t <<= 1;
		if (t & 0x100) {	/* xor the G(x)*/
			t ^= g;	/* for AES, use AES_G_POLY;*/
		}
		if (p1 & mask) {
			m ^= t;
		}
	}
	return ((u8_t) (m & 0xff));
}
#endif
void shuffle_invf_tbl(_masked_invf_t *invf)
{
	u16_t i, ri;
	u8_t nx1, nx2, *t;
	u8_t s[256];
	u32_t random;

	do {
		bcm_rng_readwords(&random, 1);
		nx1 = (u8_t) random;
	} while (nx1 == 0);

	do {
		bcm_rng_readwords(&random, 1);
		nx2 = (u8_t) random;
	} while (nx2 == 0);

	for (i = 0, t = (u8_t *) invf->tbl; i < 256; i++) {
		ri = i ^ invf->x1 ^ nx1;
		s[ri] = t[i] ^ invf->x2 ^ nx2;
	}

	for (i = 0, t = (u8_t *) invf->tbl; i < 256; i++) {
		t[i] = s[i];
	}
	invf->x1 = nx1;
	invf->x2 = nx2;
}

/*
 * Try to hide A^X. The math to use is such that
 *
 * -1 denotes inversion.
 * ((A-1)*Y)-1 ^ (X*(Y-1)) = (A)*(Y-1) ^ (X)(Y-1), then,
 * ((A)*(Y-1) ^ (X)(Y-1)) * Y = A^X
 */
u8_t gf8_get_a_xor_x(u8_t a, u8_t x, u8_t y, _masked_invf_t *invf, u8_t g)
{
	volatile u8_t t, rx, r[4];
	u32_t *pa, random;

	ARG_UNUSED(y);
	ARG_UNUSED(invf);
	ARG_UNUSED(g);
	pa = (u32_t *) &r[0];
	bcm_rng_readwords(&random, 1);
	*pa = (u32_t) random;
	__gf_dummy_op(^, ^, r[1], r[3], r[2], {
		      rx = r[0] ^ r[1] ^ r[2] ^ r[3] ^ a;
		      });
	__gf_dummy_op(^, ^, r[0], r[1], r[2], {
		      t = r[0] ^ r[2] ^ x;
		      t ^= rx ^ r[1] ^ r[3];
		      });
	return t;
}
#endif
